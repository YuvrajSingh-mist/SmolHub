âœ… Wandb initialized successfully!
ğŸ“Š Project: SmolSigLip
ğŸƒ Run: siglip_lr0.0004_bs32_epochs30
ğŸ†” Run ID: estnlde3
ğŸŒ Dashboard: https://wandb.ai/rentio/SmolSigLip/runs/estnlde3
ğŸ”§ Setting up custom metrics...
âœ… All metrics defined successfully!
Model logged to wandb - Total params: 150,910,018, Trainable: 150,910,018
ğŸ¯ Epoch 1/30:   0%|[35m                                                                                                                                   [0m| 0/30 [00:00<?, ?epoch/s][0m[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.

=== EPOCH 1/30 ===
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
ğŸš€ Epoch 01/30 | Step 00000 | Batch 001/283 | Loss: 10.195237 | LR: 0.00010000 | BS: 32
ğŸš€ Epoch 01/30 | Step 00001 | Batch 002/283 | Loss: 4.834868 | LR: 0.00010000 | BS: 32
ğŸ¯ Epoch 1/30:   0%|[35m                                                                                                                                   [0m| 0/30 [03:03<?, ?epoch/s][0m
Traceback (most recent call last):                                                                                                                                               
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 460, in <module>
    results = engine.train(model=siglip,
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 303, in train
    train_loss, train_acc = train_step(model=model,
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 55, in train_step
    for batch_idx, batch in train_pbar:
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
