‚úÖ Wandb initialized successfully!
üìä Project: SmolSigLip
üèÉ Run: siglip_lr0.0004_bs128_epochs70000
üÜî Run ID: f50wde44
üåê Dashboard: https://wandb.ai/rentio/SmolSigLip/runs/f50wde44
üîß Setting up custom metrics...
‚úÖ All metrics defined successfully!
Model logged to wandb - Total params: 214,579,970, Trainable: 214,579,970
üîç Device check before compilation:
   - Main model device: cuda:3
   - Vision model device: cuda:3
   - Text model device: cuda:3
üîß Compiling model with torch.compile...
‚úÖ Model compilation successful!
üéØ Epoch 1/70000:   0%|[35m                                                                          [0m| 0/70000 [00:00<?, ?epoch/s][0mE0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0] failed while attempting to run meta for aten.mm.default

=== EPOCH 1/70000 ===
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0] Traceback (most recent call last):0<?, ?it/s][0m
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]   File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 2427, in _dispatch_impl
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]     r = func(*args, **kwargs)
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]   File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_ops.py", line 756, in __call__
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]     return self._op(*args, **kwargs)
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]   File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_prims_common/wrappers.py", line 308, in _fn
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]     result = fn(*args, **kwargs)
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]   File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_meta_registrations.py", line 2236, in meta_mm
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]     torch._check(
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]   File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/__init__.py", line 1660, in _check
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]     _check_with(RuntimeError, cond, message)
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]   File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/__init__.py", line 1642, in _check_with
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0]     raise error_type(message_evaluated)
E0601 19:29:21.166000 4176993 site-packages/torch/_subclasses/fake_tensor.py:2431] [6/0] RuntimeError: a and b must have same reduction dim, but got [128, 1536] X [768, 1536].
üéØ Epoch 1/70000:   0%|[35m                                                                          [0m| 0/70000 [07:13<?, ?epoch/s][0m
Traceback (most recent call last):                                                                                            
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 495, in <module>
    results = engine.train(model=siglip,
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 345, in train
    train_loss, train_acc = train_step(model=model,
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 78, in train_step
    y_pred = model(batch)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 655, in _fn
    return fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 360, in forward
    embeds_text = self.text(batch['text'])
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1432, in __call__
    return self._torchdynamo_orig_callable(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1213, in __call__
    result = self._inner_convert(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 598, in __call__
    return _compile(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1059, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_utils_internal.py", line 97, in wrapper_function
    return function(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 761, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 797, in _compile_inner
    out_code = transform_code_object(code, transform)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1422, in transform_code_object
    transformations(instructions, code_options)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 257, in _fn
    return fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 715, in transform
    tracer.run()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3500, in run
    super().run()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2168, in CALL_FUNCTION
    self.call_function(fn, args, {})
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py", line 201, in realize_and_forward
    return getattr(self.realize(), name)(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/nn_module.py", line 952, in call_function
    return variables.UserFunctionVariable(fn, source=source).call_function(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 404, in call_function
    return super().call_function(tx, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 185, in call_function
    return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1187, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3726, in inline_call
    return tracer.inline_call_()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3905, in inline_call_
    self.run()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2168, in CALL_FUNCTION
    self.call_function(fn, args, {})
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/torch.py", line 1181, in call_function
    tensor_variable = wrap_fx_proxy(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2302, in wrap_fx_proxy
    return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2368, in wrap_fx_proxy_cls
    return _wrap_fx_proxy(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2464, in _wrap_fx_proxy
    example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3229, in get_fake_value
    raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3127, in get_fake_value
    ret_val = wrap_fake_exception(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 2641, in wrap_fake_exception
    return fn()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3128, in <lambda>
    lambda: run_node(tx.output, node, args, kwargs, nnmodule)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3325, in run_node
    raise RuntimeError(make_error_message(e)).with_traceback(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3284, in run_node
    return node.target(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/_stats.py", line 27, in wrapper
    return fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1282, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1823, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1384, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 2333, in _dispatch_impl
    decomposition_table[func](*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_prims_common/wrappers.py", line 308, in _fn
    result = fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_decomp/decompositions.py", line 84, in inner
    r = f(*tree_map(increase_prec, args), **tree_map(increase_prec, kwargs))
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_decomp/decompositions.py", line 1451, in addmm
    out = alpha * torch.mm(mat1, mat2)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/_stats.py", line 27, in wrapper
    return fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1282, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1823, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1384, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 2427, in _dispatch_impl
    r = func(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_ops.py", line 756, in __call__
    return self._op(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_prims_common/wrappers.py", line 308, in _fn
    result = fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_meta_registrations.py", line 2236, in meta_mm
    torch._check(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/__init__.py", line 1660, in _check
    _check_with(RuntimeError, cond, message)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/__init__.py", line 1642, in _check_with
    raise error_type(message_evaluated)
torch._dynamo.exc.TorchRuntimeError: Dynamo failed to run FX node with fake tensors: call_function <built-in function linear>(*(FakeTensor(..., device='cuda:3', size=(128, 1536), grad_fn=<Error>), Parameter(FakeTensor(..., device='cuda:3', size=(1536, 768), requires_grad=True)), Parameter(FakeTensor(..., device='cuda:3', size=(1536,), requires_grad=True))), **{}): got RuntimeError('a and b must have same reduction dim, but got [128, 1536] X [768, 1536].')

from user code:
   File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 362, in torch_dynamo_resume_in_forward_at_360
    proj_txt = torch.nn.functional.normalize(self.multimodelTextLayerPorjector(embeds_text))
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
