‚úÖ Wandb initialized successfully!
üìä Project: SmolSigLip
üèÉ Run: siglip_lr0.0004_bs128_epochs70000
üÜî Run ID: wlbt8tzb
üåê Dashboard: https://wandb.ai/rentio/SmolSigLip/runs/wlbt8tzb
üîß Setting up custom metrics...
‚úÖ All metrics defined successfully!
Model logged to wandb - Total params: 212,986,602, Trainable: 212,986,602
üéØ Epoch 1/70000:   0%|[35m                                                                          [0m| 0/70000 [05:18<?, ?epoch/s][0m

=== EPOCH 1/70000 ===
Traceback (most recent call last):                                                                                            , ?it/s][0m
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 467, in <module>
    results = engine.train(model=siglip,
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 339, in train
    train_loss, train_acc = train_step(model=model,
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 75, in train_step
    y_pred = model(batch)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 655, in _fn
    return fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 351, in forward
    embeds_text = self.text(batch['text'])
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1432, in __call__
    return self._torchdynamo_orig_callable(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1213, in __call__
    result = self._inner_convert(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 598, in __call__
    return _compile(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1059, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_utils_internal.py", line 97, in wrapper_function
    return function(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 761, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 797, in _compile_inner
    out_code = transform_code_object(code, transform)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1422, in transform_code_object
    transformations(instructions, code_options)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 257, in _fn
    return fn(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 715, in transform
    tracer.run()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3500, in run
    super().run()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2168, in CALL_FUNCTION
    self.call_function(fn, args, {})
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1170, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py", line 201, in realize_and_forward
    return getattr(self.realize(), name)(*args, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/nn_module.py", line 952, in call_function
    return variables.UserFunctionVariable(fn, source=source).call_function(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 404, in call_function
    return super().call_function(tx, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 185, in call_function
    return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1187, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3726, in inline_call
    return tracer.inline_call_()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3905, in inline_call_
    self.run()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1337, in run
    while self.step():
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1246, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 819, in wrapper
    return inner_fn(self, inst)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 421, in impl
    self.push(fn_var.call_function(self, self.popn(nargs), {}))
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py", line 1111, in call_function
    return handler(tx, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py", line 789, in <lambda>
    return lambda tx, args, kwargs: obj.call_function(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py", line 1111, in call_function
    return handler(tx, args, kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py", line 1076, in _handle_insert_op_in_graph
    return wrap_fx_proxy(tx, proxy)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2302, in wrap_fx_proxy
    return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2368, in wrap_fx_proxy_cls
    return _wrap_fx_proxy(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2464, in _wrap_fx_proxy
    example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3229, in get_fake_value
    raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3127, in get_fake_value
    ret_val = wrap_fake_exception(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 2641, in wrap_fake_exception
    return fn()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3128, in <lambda>
    lambda: run_node(tx.output, node, args, kwargs, nnmodule)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3325, in run_node
    raise RuntimeError(make_error_message(e)).with_traceback(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 3284, in run_node
    return node.target(*args, **kwargs)
torch._dynamo.exc.TorchRuntimeError: Dynamo failed to run FX node with fake tensors: call_function <built-in function getitem>(*(FakeTensor(..., device='cuda:3', size=(128, 3, 224, 224), dtype=torch.uint8), 'image'), **{}): got IndexError('too many indices for tensor of dimension 4')

from user code:
   File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 354, in torch_dynamo_resume_in_forward_at_351
    embeds_img = self.vision(batch['image'])
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 330, in forward
    inputs = self.preprocessor(images=x['image'], return_tensors="pt")

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
