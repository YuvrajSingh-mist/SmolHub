‚úÖ Wandb initialized successfully!
üìä Project: SmolSigLip
üèÉ Run: siglip_lr0.0004_bs256_epochs70000
üÜî Run ID: m55ga8sv
üåê Dashboard: https://wandb.ai/rentio/SmolSigLip/runs/m55ga8sv
üîß Setting up custom metrics...
‚úÖ All metrics defined successfully!
Model logged to wandb - Total params: 150,910,018, Trainable: 150,910,018
üéØ Epoch 1/70000:   0%|[35m                                                                                                                             [0m| 0/70000 [02:25<?, ?epoch/s][0m

=== EPOCH 1/70000 ===
Traceback (most recent call last):                                                                                                                                               , ?it/s][0m
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 461, in <module>
    results = engine.train(model=siglip,
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 307, in train
    "train_acc": [],
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/engine.py", line 59, in train_step
    for batch_idx, batch in train_pbar:
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 789, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 157, in __getitem__
    image = self._load_image_from_url(item['url'])
  File "/speech/advait/yuvraj/LLMs/SmolSigLip/train.py", line 197, in _load_image_from_url
    response = requests.get(url, timeout=timeout)
  File "/speech/advait/.local/lib/python3.10/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/speech/advait/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/speech/advait/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/speech/advait/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/speech/advait/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
KeyboardInterrupt
Exception ignored in atexit callback: <function shutdown_compile_workers at 0x7366ca5ece50>
Traceback (most recent call last):
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 113, in shutdown_compile_workers
    pool.shutdown()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 239, in shutdown
    self.process.wait(300)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/subprocess.py", line 1222, in wait
    self._wait(timeout=sigint_timeout)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/subprocess.py", line 1953, in _wait
    time.sleep(delay)
KeyboardInterrupt:
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7366e41bbf40>
Traceback (most recent call last):
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py", line 94, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py", line 226, in teardown
    self._router.join()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/speech/advait/miniconda3/envs/trainBigLlama/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt:
